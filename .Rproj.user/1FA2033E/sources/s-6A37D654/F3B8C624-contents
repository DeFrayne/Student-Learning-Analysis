---
title: "Analysis"
author: "Don DeFrayne"
date: "June 16, 2020"
output:
  html_document:
    df_print: paged
---

```{r}
#Libraries used
library(sqldf)
library(tidyr)
library(dplyr)
library(data.table)
```
  
```{r}
#This section of the code is for removing identifying student data. Do not run it on your local machine,
#as you do not have access to the source files. This is only intended to be for record-keeping purposes.

#Set the working directory to the folder containing the data
setwd("D:/Data/Learning Project")

#View the list of files in the working directory
list.files(getwd())

#Read in each gradebook file
P3Grades <- read.csv("P3 Grades.csv", stringsAsFactors = FALSE)
P4Grades <- read.csv("P4 Grades.csv", stringsAsFactors = FALSE)
P6Grades <- read.csv("P6 Grades.csv", stringsAsFactors = FALSE)

#Remove unimportant classroom information
P3Grades <- P3Grades[c(-1, -2, -34, -35),]
P4Grades <- P4Grades[c(-1, -2, -30, -31),]
P6Grades <- P6Grades[c(-1, -2, -20, -21),]

#Compact the categories so each column has a header containing all important information
P3Grades[1,] <- paste(P3Grades[1,], P3Grades[2,], P3Grades[3,], P3Grades[4,])
P4Grades[1,] <- paste(P4Grades[1,], P4Grades[2,], P4Grades[3,], P4Grades[4,])
P6Grades[1,] <- paste(P6Grades[1,], P6Grades[2,], P6Grades[3,], P6Grades[4,])

#Create new headers containing all importation information; remove spaces and periods
colnames(P3Grades) <- c("ID_Number", P3Grades[1,-1])
colnames(P4Grades) <- c("ID_Number", P4Grades[1,-1])
colnames(P6Grades) <- c("ID_Number", P6Grades[1,-1])

#Remove all superfuluous rows, since this data is now contained in the headers
P3Grades <- P3Grades[c(-1,-2,-3,-4),]
P4Grades <- P4Grades[c(-1,-2,-3,-4),]
P6Grades <- P6Grades[c(-1,-2,-3,-4),]

#Merge all 3 gradebooks into 1 file and assign ID numbers; remove spaces and periods
Grades <- rbind(P3Grades, P4Grades, P6Grades)
Grades <- Grades[,(substr(colnames(Grades),start=(nchar(colnames(Grades)))-3,nchar(colnames(Grades)))!="ASMT")]
Grades$ID_Number <- seq(1:length(Grades[,1]))
colnames(Grades) <- gsub("\\.","_",colnames(Grades))
colnames(Grades) <- gsub("\\ ","",colnames(Grades))

#Read in Spotlight
Spotlight <- read.csv("Spotlight.csv", stringsAsFactors = FALSE)

#Join Grades and Spotlight
Grades_Spotlight <- left_join(Grades, Spotlight, by=c("LastName", "FirstName"))

#Read in each quarter exam. There was no Q4 exam due to coronavirus; it was canceled.
Q1Exam <- read.csv("Q1 Exam.csv", stringsAsFactors = FALSE)
Q2Exam <- read.csv("Q2 Exam.csv", stringsAsFactors = FALSE)
Q3Exam <- read.csv("Q3 Exam.csv", stringsAsFactors = FALSE)

#Change column names to specify which exam each file refers to
colnames(Q1Exam)[3] <- "Q1Exam"
colnames(Q2Exam)[3] <- "Q2Exam"
colnames(Q3Exam)[3] <- "Q3Exam"

#Change column names for each question to reflect which exam they are from
for(i in 4:28){
  colnames(Q1Exam)[i] <- paste0("E1Q",i-3)
  }

for(i in 4:28){
  colnames(Q2Exam)[i] <- paste0("E2Q",i-3)
  }

for(i in 4:28){
  colnames(Q3Exam)[i] <- paste0("E3Q",i-3)
}

#Read in Contact and FSA
Contact <- read.csv("Contact.csv", stringsAsFactors = FALSE)
FSA <- read.csv("FSA.csv", stringsAsFactors = FALSE)

#Join Grades_Spotlight with Exams, Contact, and FSA
Grades_Spotlight_Exams <- left_join(Grades_Spotlight, Q1Exam, by=c("LastName"="Last.Name", "FirstName"="First.Name"))
Grades_Spotlight_Exams <- left_join(Grades_Spotlight_Exams, Q2Exam, by=c("LastName"="Last.Name", "FirstName"="First.Name"))
Grades_Spotlight_Exams <- left_join(Grades_Spotlight_Exams, Q3Exam, by=c("LastName"="Last.Name", "FirstName"="First.Name"))
Grades_Spotlight_Exams_Contact <- left_join(Grades_Spotlight_Exams, Contact, by=c("StudentId"="Other.ID"))
All_Data <- left_join(Grades_Spotlight_Exams_Contact, FSA, by=c("StudentId"="Student.Id"))

#Read in the Khan Academy files
P3Khan <- read.csv("P3 Khan.csv", stringsAsFactors = FALSE)
P4Khan <- read.csv("P4 Khan.csv", stringsAsFactors = FALSE)
P6Khan <- read.csv("P6 Khan.csv", stringsAsFactors = FALSE)

#Add a new column called ID_Number; this is not the StudentID, but the anonymous signifier
P3Khan[,11] <- ""
P4Khan[,11] <- ""
P6Khan[,11] <- ""
colnames(P3Khan)[11] <- "ID_Number"
colnames(P4Khan)[11] <- "ID_Number"
colnames(P6Khan)[11] <- "ID_Number"

#Replace all "." with "_", because sqldf has trouble reading names that contain "."
colnames(P3Khan) <- gsub("\\.","_",colnames(P3Khan))
colnames(P4Khan) <- gsub("\\.","_",colnames(P4Khan))
colnames(P6Khan) <- gsub("\\.","_",colnames(P6Khan))

#Remove students that are no longer in the class for Period 3, and any null value entries
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Student_Name NOT LIKE ('%ord, Ra%')")
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Student_Name NOT LIKE ('%alez, Ma%')")
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Student_Name NOT LIKE ('%ins, As%')")
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Student_Name NOT LIKE ('%as, Ter%')")
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Student_Name NOT LIKE ('%ey, C%')")
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Student_Name NOT LIKE ('null')")

#Remove students that are no longer in the class for Period 4, and any null value entries
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('%alez, Ma%')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('%ett, J%')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('%iz, De%')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('%bb, Dy%')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('%ore, Mi%')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('%urt, Ki%')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Student_Name NOT LIKE ('null')")

#Remove students that are no longer in the class for Period 6, and any null value entries
P6Khan <- sqldf("SELECT * FROM P6Khan WHERE Student_Name NOT LIKE ('%nes, N%')")
P6Khan <- sqldf("SELECT * FROM P6Khan WHERE Student_Name NOT LIKE ('%is, Lu%')")
P6Khan <- sqldf("SELECT * FROM P6Khan WHERE Student_Name NOT LIKE ('%lu, Z%')")
P6Khan <- sqldf("SELECT * FROM P6Khan WHERE Student_Name NOT LIKE ('null')")

#Split the Khan file's Student.Name into two columns and remove spaces
P3Khan <- separate(P3Khan, Student_Name, c("LastName", "FirstName"), ",")
P4Khan <- separate(P4Khan, Student_Name, c("LastName", "FirstName"), ",")
P6Khan <- separate(P6Khan, Student_Name, c("LastName", "FirstName"), ",")
P3Khan$FirstName <- substr(P3Khan$FirstName, 2, nchar(P3Khan$FirstName))
P4Khan$FirstName <- substr(P4Khan$FirstName, 2, nchar(P4Khan$FirstName))
P6Khan$FirstName <- substr(P6Khan$FirstName, 2, nchar(P6Khan$FirstName))

#Assign the ID_Number based on Student.Name content in All_Datax 
for(i in 1:nrow(P3Khan)){
  P3Khan[i,12] <- All_Data[which(All_Data$LastName.x==toupper(P3Khan[i,2]) &
                              All_Data$FirstName.x==toupper(P3Khan[i,3])),1]
}

for(i in 1:nrow(P4Khan)){
  P4Khan[i,12] <- All_Data[which(All_Data$LastName.x==toupper(P4Khan[i,2]) &
                              All_Data$FirstName.x==toupper(P4Khan[i,3])),1]
}

for(i in 1:nrow(P6Khan)){
  P6Khan[i,12] <- All_Data[which(All_Data$LastName.x==toupper(P6Khan[i,2]) &
                              All_Data$FirstName.x==toupper(P6Khan[i,3])),1]
}

#Remove all Videos and Articles from the Khan files, since they are ungraded and contain no useful information
P3Khan <- sqldf("SELECT * FROM P3Khan WHERE Assignment_Type NOT IN('Video', 'Article')")
P4Khan <- sqldf("SELECT * FROM P4Khan WHERE Assignment_Type NOT IN('Video', 'Article')")
P6Khan <- sqldf("SELECT * FROM P6Khan WHERE Assignment_Type NOT IN('Video', 'Article')")

#Remove FirstName and LastName so the data is now anonymous, but still connected to All_Data through the ID_Number
P3Khan <- P3Khan[,c(-2,-3)]
P4Khan <- P4Khan[,c(-2,-3)]
P6Khan <- P6Khan[,c(-2,-3)]

#Reorder Khan file columns so that ID_Number is first, and then merge
P3Khan <- P3Khan[,c(10,seq(1:9))]
P4Khan <- P4Khan[,c(10,seq(1:9))]
P6Khan <- P6Khan[,c(10,seq(1:9))]
Khan <- rbind(P3Khan, P4Khan, P6Khan)

#Remove all identifying information from All_Data
All_Data$FirstName.x <- NULL
All_Data$LastName.x <- NULL
All_Data$FirstName.y <- NULL
All_Data$LastName.y <- NULL
All_Data$Advisor.x <- NULL
All_Data$Advisor.y <- NULL
All_Data$First <- NULL
All_Data$Last.Name <- NULL
All_Data$Middle <- NULL
All_Data$Birthdate <- NULL
All_Data$Student.Key <- NULL
All_Data$StudentId <- NULL
All_Data$FL.Ed.ID <- NULL
All_Data$ProviderName <- NULL
All_Data$Testing.Provider <- NULL

#Remove columns with no data, uniform data, or superfluous data
All_Data$Period.Attend.Sem.1_Attendance <- NULL
All_Data$Period.Attend.Sem.1_Course.s. <- NULL
All_Data$Period.Attend.Sem.2_Attendance <- NULL
All_Data$Period.Attend.Sem.2_Course.s. <- NULL
All_Data$Counselor <- NULL
All_Data$FSA.EL_Performance.Level <- NULL
All_Data$FSA.MA_Performance.Level <- NULL
All_Data$A1.PL_Performance.Level <- NULL
All_Data$iEL.SS_Performance.Level <- NULL
All_Data$S <- NULL
All_Data$GT.S <- NULL
All_Data$Schl <- NULL
All_Data$DE <- NULL
All_Data$GY <- NULL
All_Data$ELA.Test.Date <- NULL
All_Data$ELA.Test.Date.1 <- NULL
All_Data$Testing.Grade <- NULL
All_Data$Algebra.1.Test.Date <- NULL
All_Data$Algebra.1.Test.Date.1 <- NULL
All_Data$Other.Grades_Course <- NULL
All_Data$Other.Grades_Most.Recent.Grade <- NULL
All_Data$MA.SS_Performance.Level <- NULL
All_Data$GEO.PL_Performance.Level <- NULL
All_Data$GEO.SS_Performance.Level <- NULL
All_Data$iEL.PR_Performance.Level <- NULL
All_Data$iMa.SS_Performance.Level <- NULL
All_Data$iMa.PR_Performance.Level <- NULL
All_Data$Grad.Base.Year_Year <- NULL
All_Data$Graduation.Base.Year <- NULL
All_Data$ELA.Percentile.Rank <- NULL
All_Data$ELA.Percentile.Rank.1 <- NULL
All_Data$Geometry.Percentile.Rank <- NULL
All_Data$Algebra.1.Percentile.Rank <- NULL
All_Data$Algebra.1.Percentile.Rank.1 <- NULL
All_Data$X.2 <- NULL
All_Data$X.3 <- NULL

#Remove all but the area code and zip code from phone and address information
All_Data$Primary.Phone.. <- substr(All_Data$Primary.Phone..,2,4)
All_Data$Address <- substr(All_Data$Address, start=(nchar(All_Data$Address)-4),nchar(All_Data$Address))

#Rename some columns for ease of intrepretability
colnames(Data)[which(colnames(Data)=="Q1Exam")] <- "Q1Exam"
colnames(Data)[which(colnames(Data)=="Q2Exam")] <- "Q2Exam"
colnames(Data)[which(colnames(Data)=="Q3Exam")] <- "Q3Exam"

#This is for calculating the Khan Ordinal Score, used as a potential regression approach
Khan[1,11] <- ""
colnames(Khan)[11] <- "Ordinal_Score"
for(i in 1:nrow(Khan)){
  if (is.na(Khan[i,4]/Khan[i,5]))
  {
    Khan[i,11] <- 0
  }
  else if (Khan[i,4]/Khan[i,5] <= .2)
  {
    Khan[i,11] <- 0
  }
  else if (Khan[i,4]/Khan[i,5] <= .4)
  {
    Khan[i,11] <- 1
  }
  else if (Khan[i,4]/Khan[i,5] <= .6)
  {
    Khan[i,11] <- 2
  }
  else if (Khan[i,4]/Khan[i,5] <= .8)
  {
    Khan[i,11] <- 3
  }
  else if (Khan[i,4]/Khan[i,5] <= 1)
  {
    Khan[i,11] <- 4
  }
}

#Write the .csv files to the Git directory to begin analysis
setwd("D:/Git/Student Learning Analysis")
write.csv(All_Data, "Data.csv", row.names=FALSE)
write.csv(Khan, "Khan.csv", row.names=FALSE)
```

```{r}
#Use this file to read in the relevant data sets as needed; mostly used for refreshing files during EDA

#Read in data sets
setwd("D:/Git/Student Learning Analysis")
Data <- read.csv("Data.csv", stringsAsFactors = FALSE)
Khan <- read.csv("Khan.csv", stringsAsFactors = FALSE)

#See all due dates in Khan file
unique(Khan$Due_Date)

#Create the correlation table to examine the relationship between different Khan scoring strategies and exam results
#20% cutoff gives 1 point per Khan score 20% or above
#50% cutoff gives 1 point per Khan score 50% or above
#70% cutoff gives 1 point per Khan score 70% or above
#100% cutoff gives 1 point per Khan score at 100%
#Partial Scoring gives 0.5 points per 70%+, which becomes 1 point at 100%
#Ordinal Scoring assigns 1 point per 20% attained for each Khan topic; so a 55% is worth 3 points
#Raw Sum Score adds up the base Khan scores with no alteration
#The goal of Scoring_Matrix is to look at different scoring methods to determine which approach demonstrates
#the strongest relationship between Khan assignments and Exam scores
#Students are initially graded on 70%+ as full credit, so bias goes toward the 70% cutoff appraoch
Scoring_Matrix <- matrix(nrow=3, ncol=7)
rownames(Scoring_Matrix) <- c("Q1Exam", "Q2Exam", "Q3Exam")
colnames(Scoring_Matrix) <- c("20% Cutoff", "50% Cutoff", "70% Cutoff", "100% Cutoff", "Partial Score", "Ordinal Score", "Raw Sum Score")
```

```{r}
#Quarter 1 Exam Analysis

#Count completed Khan Academy topics with a 20% score or higher for quarter 1;
#This is as close to "class participation" as the scores can be, since students can often guess 20%+ of the answers correct
Q1Khan0.2 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.2) AS 'Q1KhanScore0.2'
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")

#Merge Khan Academy score with Data by ID_Number
Data <- left_join(Data, Q1Khan0.2, by='ID_Number')

#Quick look at the relationship between Q1 Exam Scores and Khan topics completed
summary(lm(Data$Q1Exam ~ Data$Q1KhanScore0.2))
(round(cor(Data$Q1Exam, Data$Q1KhanScore0.2, use="complete.obs"),4) -> Scoring_Matrix[1,1])
plot(Data$Q1Exam, Data$Q1KhanScore0.2)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanScore0.2))

#The above regression establishes the Khan Academy scores as statistically significant predicts
#even when students only require a 20% score or higher. The below code repeats the regression for
#the 50% as the prerequisite for receiving credit.
Q1Khan0.5 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.5) AS 'Q1KhanScore0.5'
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q1Khan0.5, by='ID_Number')
summary(lm(Data$Q1Exam ~ Data$Q1KhanScore0.5))
(round(cor(Data$Q1Exam, Data$Q1KhanScore0.5, use="complete.obs"),4) -> Scoring_Matrix[1,2])
plot(Data$Q1Exam, Data$Q1KhanScore0.5)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanScore0.5))

#Using a 50% barrier improved the correlation, R-squared value, and statistical significance of the regression.
#It is reasonable to increase the barrier again to determine if more stringent requirements establish a stronger trend.
#70% will now be used as the prerequisite for receiving credit.
Q1Khan0.7 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.7) AS 'Q1KhanScore0.7'
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q1Khan0.7, by='ID_Number')
summary(lm(Data$Q1Exam ~ Data$Q1KhanScore0.7))
(round(cor(Data$Q1Exam, Data$Q1KhanScore0.7, use="complete.obs"), 4) -> Scoring_Matrix[1,3])
plot(Data$Q1Exam, Data$Q1KhanScore0.7)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanScore0.7))

#A 70% prerequisite for receiving Khan Academy credit again improved the correlation, R-squared value, and
#statistical significance of the regression. 100% will now be used.
Q1Khan1.0 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0) AS 'Q1KhanScore1.0'
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q1Khan1.0, by='ID_Number')
summary(lm(Data$Q1Exam ~ Data$Q1KhanScore1.0))
(round(cor(Data$Q1Exam, Data$Q1KhanScore1.0, use="complete.obs"), 4) -> Scoring_Matrix[1,4])
plot(Data$Q1Exam, Data$Q1KhanScore1.0)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanScore1.0))

#An attempt to determine if assigning partial (0.5 points) credit for a 70% and full credit (1 point) at
#100% provides a better regression than 70% or 100% alone.
Q1KhanPartial <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0)+
  (SUM(1.0*Score_Best_Ever/Points_Possible >= 0.7)-
  SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0))*.5 AS Q1KhanPartial
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q1KhanPartial, by='ID_Number')
summary(lm(Data$Q1Exam ~ Data$Q1KhanPartial))
(round(cor(Data$Q1Exam, Data$Q1KhanPartial, use="complete.obs"), 4) -> Scoring_Matrix[1,5])
plot(Data$Q1Exam, Data$Q1KhanPartial)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanPartial))

#An attempt to determine if assigning 1 point per 20% correct provides a better regression
#Score is pre-calculated in the first coding block for efficiency
Q1KhanOrdinal <- sqldf("SELECT ID_Number,
	SUM(Ordinal_Score) AS Q1KhanOrdinal
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q1KhanOrdinal, by='ID_Number')
summary(lm(Data$Q1Exam ~ Data$Q1KhanOrdinal))
(round(cor(Data$Q1Exam, Data$Q1KhanOrdinal, use="complete.obs"), 4) -> Scoring_Matrix[1,6])
plot(Data$Q1Exam, Data$Q1KhanOrdinal)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanOrdinal))

#Raw score for regression comparison
Q1KhanRaw <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible) Q1KhanRaw
	FROM Khan
	WHERE (Due_Date LIKE ('Aug%')
		OR Due_Date LIKE ('Sep%')
		OR Due_Date LIKE ('Oct 5%')
		OR Due_Date LIKE ('Oct 12%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q1KhanRaw, by='ID_Number')
summary(lm(Data$Q1Exam ~ Data$Q1KhanRaw))
(round(cor(Data$Q1Exam, Data$Q1KhanRaw, use="complete.obs"), 4) -> Scoring_Matrix[1,7])
plot(Data$Q1Exam, Data$Q1KhanRaw)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q1Exam ~ Data$Q1KhanRaw))
```

```{r}
#Quarter 2 Exam Analysis

#Since the Quarter 1 Exam showed improving regression values with increasing grading standards, I will explore
#that same relationship for Quarter 2
Q2Khan0.2 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.2) AS 'Q2KhanScore0.2'
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")

#Merge Khan Academy score with Data by ID_Number
Data <- left_join(Data, Q2Khan0.2, by='ID_Number')

#Quick look at the relationship between Q2 Exam Scores and Khan topics completed
summary(lm(Data$Q2Exam ~ Data$Q2KhanScore0.2))
(round(cor(Data$Q2Exam, Data$Q2KhanScore0.2, use="complete.obs"), 4) -> Scoring_Matrix[2,1])
plot(Data$Q2Exam, Data$Q2KhanScore0.2)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanScore0.2))

#The above regression establishes the Khan Academy scores as statistically significant predicts
#even when students only require a 20% score or higher. The below code repeats the regression for
#the 50% as the prerequisite for receiving credit.
Q2Khan0.5 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.5) AS 'Q2KhanScore0.5'
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q2Khan0.5, by='ID_Number')
summary(lm(Data$Q2Exam ~ Data$Q2KhanScore0.5))
(round(cor(Data$Q2Exam, Data$Q2KhanScore0.5, use="complete.obs"), 4) -> Scoring_Matrix[2,2])
plot(Data$Q2Exam, Data$Q2KhanScore0.5)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanScore0.5))

#Using a 50% barrier improved the correlation, R-squared value, and statistical significance of the regression.
#It is reasonable to increase the barrier again to determine if more stringent requirements establish a stronger trend.
#70% will now be used as the prerequisite for receiving credit.
Q2Khan0.7 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.7) AS 'Q2KhanScore0.7'
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q2Khan0.7, by='ID_Number')
summary(lm(Data$Q2Exam ~ Data$Q2KhanScore0.7))
(round(cor(Data$Q2Exam, Data$Q2KhanScore0.7, use="complete.obs"), 4) -> Scoring_Matrix[2,3])
plot(Data$Q2Exam, Data$Q2KhanScore0.7)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanScore0.7))

#A 70% prerequisite for receiving Khan Academy credit again improved the correlation, R-squared value, and
#statistical significance of the regression. 100% will now be used.
Q2Khan1.0 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0) AS 'Q2KhanScore1.0'
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q2Khan1.0, by='ID_Number')
summary(lm(Data$Q2Exam ~ Data$Q2KhanScore1.0))
(round(cor(Data$Q2Exam, Data$Q2KhanScore1.0, use="complete.obs"), 4) -> Scoring_Matrix[2,4])
plot(Data$Q2Exam, Data$Q2KhanScore1.0)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanScore1.0))

#An attempt to determine if assigning partial (0.5 points) credit for a 70% and full credit (1 point) at
#100% provides a better regression than 70% or 100% alone.
Q2KhanPartial <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0)+
  (SUM(1.0*Score_Best_Ever/Points_Possible >= 0.7)-
  SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0))*.5 AS Q2KhanPartial
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q2KhanPartial, by='ID_Number')
summary(lm(Data$Q2Exam ~ Data$Q2KhanPartial))
(round(cor(Data$Q2Exam, Data$Q2KhanPartial, use="complete.obs"), 4) -> Scoring_Matrix[2,5])
plot(Data$Q2Exam, Data$Q2KhanPartial)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanPartial))

#An attempt to determine if assigning 1 point per 20% correct provides a better regression
#Score is pre-calculated in the first coding block for efficiency
Q2KhanOrdinal <- sqldf("SELECT ID_Number,
	SUM(Ordinal_Score) AS Q2KhanOrdinal
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q2KhanOrdinal, by='ID_Number')
summary(lm(Data$Q2Exam ~ Data$Q2KhanOrdinal))
(round(cor(Data$Q2Exam, Data$Q2KhanOrdinal, use="complete.obs"), 4) -> Scoring_Matrix[2,6])
plot(Data$Q2Exam, Data$Q2KhanOrdinal)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanOrdinal))

#Raw score for regression comparison
Q2KhanRaw <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible) Q2KhanRaw
	FROM Khan
	WHERE (Due_Date LIKE ('Oct 26%')
		OR Due_Date LIKE ('Nov%')
		OR Due_Date LIKE ('Dec%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q2KhanRaw, by='ID_Number')
summary(lm(Data$Q2Exam ~ Data$Q2KhanRaw))
(round(cor(Data$Q2Exam, Data$Q2KhanRaw, use="complete.obs"), 4) -> Scoring_Matrix[2,7])
plot(Data$Q2Exam, Data$Q2KhanRaw)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q2Exam ~ Data$Q2KhanRaw))
```

```{r}
#Quarter 3 Exam Analysis

#Since the Quarter 1 Exam showed improving regression values with increasing grading standards, I will explore
#that same relationship for Quarter 2
Q3Khan0.2 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.2) AS 'Q3KhanScore0.2'
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")

#Merge Khan Academy score with Data by ID_Number
Data <- left_join(Data, Q3Khan0.2, by='ID_Number')

#Quick look at the relationship between Q3 Exam Scores and Khan topics completed
summary(lm(Data$Q3Exam ~ Data$Q3KhanScore0.2))
(round(cor(Data$Q3Exam, Data$Q3KhanScore0.2, use="complete.obs"), 4) -> Scoring_Matrix[3,1])
plot(Data$Q3Exam, Data$Q3KhanScore0.2)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanScore0.2))

#The above regression establishes the Khan Academy scores as statistically significant predicts
#even when students only require a 20% score or higher. The below code repeats the regression for
#the 50% as the prerequisite for receiving credit.
Q3Khan0.5 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.5) AS 'Q3KhanScore0.5'
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q3Khan0.5, by='ID_Number')
summary(lm(Data$Q3Exam ~ Data$Q3KhanScore0.5))
(round(cor(Data$Q3Exam, Data$Q3KhanScore0.5, use="complete.obs"), 4) -> Scoring_Matrix[3,2])
plot(Data$Q3Exam, Data$Q3KhanScore0.5)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanScore0.5))

#Using a 50% barrier improved the correlation, R-squared value, and statistical significance of the regression.
#It is reasonable to increase the barrier again to determine if more stringent requirements establish a stronger trend.
#70% will now be used as the prerequisite for receiving credit.
Q3Khan0.7 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 0.7) AS 'Q3KhanScore0.7'
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q3Khan0.7, by='ID_Number')
summary(lm(Data$Q3Exam ~ Data$Q3KhanScore0.7))
(round(cor(Data$Q3Exam, Data$Q3KhanScore0.7, use="complete.obs"), 4) -> Scoring_Matrix[3,3])
plot(Data$Q3Exam, Data$Q3KhanScore0.7)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanScore0.7))

#A 70% prerequisite for receiving Khan Academy credit again improved the correlation, R-squared value, and
#statistical significance of the regression. 100% will now be used.
Q3Khan1.0 <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0) AS 'Q3KhanScore1.0'
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q3Khan1.0, by='ID_Number')
summary(lm(Data$Q3Exam ~ Data$Q3KhanScore1.0))
(round(cor(Data$Q3Exam, Data$Q3KhanScore1.0, use="complete.obs"), 4) -> Scoring_Matrix[3,4])
plot(Data$Q3Exam, Data$Q3KhanScore1.0)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanScore1.0))

#An attempt to determine if assigning partial (0.5 points) credit for a 70% and full credit (1 point) at
#100% provides a better regression than 70% or 100% alone.
Q3KhanPartial <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0)+
  (SUM(1.0*Score_Best_Ever/Points_Possible >= 0.7)-
  SUM(1.0*Score_Best_Ever/Points_Possible >= 1.0))*.5 AS Q3KhanPartial
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q3KhanPartial, by='ID_Number')
summary(lm(Data$Q3Exam ~ Data$Q3KhanPartial))
(round(cor(Data$Q3Exam, Data$Q3KhanPartial, use="complete.obs"), 4) -> Scoring_Matrix[3,5])
plot(Data$Q3Exam, Data$Q3KhanPartial)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanPartial))

#An attempt to determine if assigning 1 point per 20% correct provides a better regression
#Score is pre-calculated in the first coding block for efficiency
Q3KhanOrdinal <- sqldf("SELECT ID_Number,
	SUM(Ordinal_Score) AS Q3KhanOrdinal
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q3KhanOrdinal, by='ID_Number')
summary(lm(Data$Q3Exam ~ Data$Q3KhanOrdinal))
(round(cor(Data$Q3Exam, Data$Q3KhanOrdinal, use="complete.obs"), 4) -> Scoring_Matrix[3,6])
plot(Data$Q3Exam, Data$Q3KhanOrdinal)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanOrdinal))

#Raw score for regression comparison
Q3KhanRaw <- sqldf("SELECT ID_Number,
	SUM(1.0*Score_Best_Ever/Points_Possible) Q3KhanRaw
	FROM Khan
	WHERE (Due_Date LIKE ('Jan%')
		OR Due_Date LIKE ('Feb%'))
	GROUP BY ID_Number
	")
Data <- left_join(Data, Q3KhanRaw, by='ID_Number')
summary(lm(Data$Q3Exam ~ Data$Q3KhanRaw))
(round(cor(Data$Q3Exam, Data$Q3KhanRaw, use="complete.obs"), 4) -> Scoring_Matrix[3,7])
plot(Data$Q3Exam, Data$Q3KhanRaw)
#Commented out for ease of chunking the code; errors are approximately normal
#plot(lm(Data$Q3Exam ~ Data$Q3KhanRaw))
```
